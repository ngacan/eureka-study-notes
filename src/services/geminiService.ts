// ============================================================================
// ‚úÖ FIX HO√ÄN CH·ªàNH CHO L·ªñI 404 / 503 / process undefined / fallback model
// ============================================================================

/* global window */
if (typeof window !== "undefined" && typeof (window as any).process === "undefined") {
  (window as any).process = { env: { NODE_ENV: "production" } };
}

import type { Note, ProgressAnalysis } from "../types";

// ============================================================================
// ‚öôÔ∏è H√ÄM FETCH TR·ª∞C TI·∫æP API GOOGLE GENERATIVE AI
// ============================================================================

const API_KEY = import.meta.env.VITE_API_KEY;

const MODEL_PRIORITIES = [
  "gemini-2.0-flash",
  "gemini-2.0-pro",
  "gemini-1.5-flash",
  "gemini-1.5-pro",
  "gemini-pro",
];

// üß† H√†m g·ªçi model c√≥ fallback t·ª± ƒë·ªông
async function safeGenerateContent(prompt: string): Promise<string> {
  if (!API_KEY) {
    console.error("‚ùå Thi·∫øu API Key! H√£y th√™m VITE_API_KEY v√†o .env.local");
    return "‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh API Key cho AI.";
  }

  for (const modelName of MODEL_PRIORITIES) {
    try {
      console.log("üß† ƒêang g·ªçi model:", modelName);

      const url = `https://generativelanguage.googleapis.com/v1/models/${modelName}:generateContent?key=${API_KEY}`;
      const response = await fetch(url, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{ parts: [{ text: prompt }] }],
        }),
      });

      if (!response.ok) {
        const errText = await response.text();
        console.warn(`‚ö†Ô∏è Model ${modelName} l·ªói ${response.status}: ${errText}`);
        if (response.status === 404 || response.status === 503) continue;
        throw new Error(`L·ªói API ${response.status}`);
      }

      const data = await response.json();
      const text =
        data?.candidates?.[0]?.content?.parts?.[0]?.text?.trim() ??
        "‚ö†Ô∏è Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ AI.";
      return text;
    } catch (err: any) {
      console.error("AI Error:", err);
      continue;
    }
  }

  return "‚ö†Ô∏è T·∫•t c·∫£ model ƒë·ªÅu kh√¥ng kh·∫£ d·ª•ng l√∫c n√†y. H√£y th·ª≠ l·∫°i sau.";
}

/*
  Replace direct top-level GoogleGenAI usage with a safe wrapper that:
  - uses server-side @google/genai when running on Node and API_KEY is present
  - falls back to calling a /api/genai proxy when running in the browser (recommended)
*/
const apiKey = process.env.API_KEY;

async function callGenAi(prompt: string, model = "gemini-2.5-pro", config?: any) {
  // Server-side: use official SDK when API key is available
  if (typeof window === "undefined" && apiKey) {
    const { GoogleGenAI } = await import("@google/genai");
    const ai = new GoogleGenAI({ apiKey: apiKey as string });
    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config,
    });
    return response.text;
  }

  // Client-side or no API key: call a server proxy endpoint you must implement (/api/genai)
  const resp = await fetch("/api/genai", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ prompt, model, config }),
  });
  if (!resp.ok) {
    const txt = await resp.text().catch(() => "");
    throw new Error(`GenAI proxy error ${resp.status}: ${txt}`);
  }
  const body = await resp.json().catch(() => ({}));
  return body.text ?? body;
}

// Then use callGenAi(...) in analyzeMistakes and analyzeProgress
export const analyzeMistakes = async (notes: Note[]): Promise<string> => {
  if (notes.length === 0) return "Ch∆∞a c√≥ ghi ch√∫ n√†o ƒë·ªÉ ph√¢n t√≠ch. H√£y th√™m ghi ch√∫ tr∆∞·ªõc nh√©!";
  try {
    const prompt = `
    D·ª±a tr√™n c√°c ghi ch√∫ h·ªçc t·∫≠p sau, h√£y ƒë√≥ng vai m·ªôt hu·∫•n luy·ªán vi√™n h·ªçc t·∫≠p chuy√™n nghi·ªáp.
    Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
    1. N√™u 2-3 d·∫°ng l·ªói sai ph·ªï bi·∫øn nh·∫•t v√† nguy√™n nh√¢n g·ªëc r·ªÖ.
    2. G·ª£i √Ω 3 chi·∫øn l∆∞·ª£c ho·∫∑c b√†i t·∫≠p c·ª• th·ªÉ ƒë·ªÉ c·∫£i thi·ªán.
    H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, b·∫±ng ti·∫øng Vi·ªát, c√≥ ƒë·ªãnh d·∫°ng markdown.

    D·ªØ li·ªáu ghi ch√∫:
    ${JSON.stringify(notes, null, 2)}
    `;
    const text = await callGenAi(prompt, "gemini-2.5-flash");
    return typeof text === "string" ? text : JSON.stringify(text);
  } catch (err) {
    console.error("analyzeMistakes error", err);
    return "‚ö†Ô∏è Kh√¥ng th·ªÉ ph√¢n t√≠ch l·ªói. Vui l√≤ng th·ª≠ l·∫°i sau.";
  }
};

export const analyzeProgress = async (notes: Note[]): Promise<ProgressAnalysis> => {
  if (notes.length === 0) {
    return {
      evaluation: "Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° ti·∫øn ƒë·ªô.",
      chartDataByDifficulty: [],
      chartDataBySubject: [],
    };
  }
  try {
    const prompt = `
    H√£y ph√¢n t√≠ch ti·∫øn ƒë·ªô h·ªçc t·∫≠p d·ª±a tr√™n c√°c ghi ch√∫ sau:
    - Nh√≥m ghi ch√∫ theo th√°ng.
    - ƒê·∫øm s·ªë l∆∞·ª£ng l·ªói theo ƒë·ªô kh√≥ v√† m√¥n h·ªçc.
    - Vi·∫øt ƒëo·∫°n nh·∫≠n x√©t ƒë·ªông vi√™n ng·∫Øn g·ªçn (2‚Äì4 c√¢u) v·ªÅ xu h∆∞·ªõng h·ªçc t·∫≠p.
    Tr·∫£ v·ªÅ JSON g·ªìm: "evaluation", "chartDataByDifficulty", "chartDataBySubject".

    D·ªØ li·ªáu:
    ${JSON.stringify(notes, null, 2)}
    `;
    const config = {
      responseMimeType: "application/json",
      // you may include responseSchema when calling server-side SDK
    };
    const text = await callGenAi(prompt, "gemini-2.5-pro", config);
    // try parse JSON safely
    const trimmed = (text || "").trim();
    try {
      const parsed = JSON.parse(trimmed);
      return parsed as ProgressAnalysis;
    } catch {
      return {
        evaluation: typeof text === "string" ? text : JSON.stringify(text),
        chartDataByDifficulty: [],
        chartDataBySubject: [],
      };
    }
  } catch (err) {
    console.error("analyzeProgress error", err);
    return {
      evaluation: "‚ö†Ô∏è L·ªói khi ph√¢n t√≠ch ti·∫øn ƒë·ªô. Vui l√≤ng th·ª≠ l·∫°i.",
      chartDataByDifficulty: [],
      chartDataBySubject: [],
    };
  }
};
